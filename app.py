import streamlit as st
import pandas as pd
import jieba
import jieba.analyse
from snownlp import SnowNLP
import warnings
import random
import re
from datetime import datetime
import numpy as np

# ========== åŸºç¡€é…ç½® ==========
warnings.filterwarnings('ignore')
st.set_page_config(page_title="æ¸¸æˆæµ‹è¯•ç¾¤èˆ†æƒ…åˆ†æå·¥å…·", layout="wide")
st.title("ğŸ® æ¸¸æˆæµ‹è¯•ç¾¤èˆ†æƒ…åˆ†æå·¥å…·ï¼ˆé¢è¯•å®Œæ•´ç‰ˆï¼‰")

# ========== å·¥å…·å‡½æ•°ï¼šå®‰å…¨å¤„ç†æ•°å€¼ ==========
def safe_divide(a, b, default=0.0):
    """å®‰å…¨é™¤æ³•ï¼Œé¿å…é™¤é›¶é”™è¯¯"""
    try:
        return a / b if b != 0 else default
    except:
        return default

def clamp_value(value, min_val=0.0, max_val=1.0):
    """å°†æ•°å€¼é™åˆ¶åœ¨æŒ‡å®šèŒƒå›´"""
    return max(min_val, min(max_val, value))

# ========== æ ¸å¿ƒè§£æå‡½æ•°ï¼ˆå®Œå…¨ä¿ç•™ï¼‰==========
def parse_txt_chat(chat_text, custom_module_rules):
    lines = chat_text.split('\n')
    structured_data = []
    chat_id = 1
    module_keywords = custom_module_rules if custom_module_rules else {
        "è£…å¤‡ç³»ç»Ÿ": ["è£…å¤‡", "æ•°å€¼", "å¼ºåŒ–", "æ‰è½", "å……å€¼", "é“å…·"],
        "ç©æ³•æœºåˆ¶": ["å‰¯æœ¬", "æŠ€èƒ½", "è¿æ‹›", "æ•°å€¼å¹³è¡¡", "æ´»åŠ¨", "éš¾åº¦"],
        "æŠ½å¡ç³»ç»Ÿ": ["æŠ½å¡", "æ¦‚ç‡", "ä¿åº•", "æ–°å¡", "æ¬¡æ•°"],
        "å®¢æœäº’åŠ¨": ["å®¢æœ", "å“åº”", "åé¦ˆ", "è§£å†³", "æ€åº¦"],
        "ç‰ˆæœ¬æ›´æ–°": ["ç‰ˆæœ¬", "æ›´æ–°", "å¡é¡¿", "BUG", "æ›´æ–°åŒ…"],
        "ç¤¾äº¤é—²èŠ": ["ç»„é˜Ÿ", "èŠå¤©", "å¥½å‹", "å…¬ä¼š", "æˆªå›¾"],
        "BUGåé¦ˆ": ["é—ªé€€", "å¡é¡¿", "BUG", "å´©æºƒ", "å¤–æŒ‚", "ç™»å½•"],
        "è¿›åº¦åˆ†äº«": ["å‡çº§", "é€šå…³", "è¿›åº¦", "ä»»åŠ¡", "å¥–åŠ±"]
    }
    time_patterns = [
        r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]',
        r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) -',
        r'(\d{2}-\d{2} \d{2}:\d{2}:\d{2})',
        r'(\d{2}:\d{2}:\d{2})'
    ]
    for line in lines:
        line = line.strip()
        if not line or len(line) < 2 or line.isspace() or re.match(r'^[\W_]+$', line):
            continue
        create_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        user_id = f"user{random.randint(1, 500)}"
        content = line
        for pattern in time_patterns:
            time_match = re.search(pattern, line)
            if time_match:
                time_str = time_match.group(1)
                if len(time_str.split('-')) == 1:
                    time_str = f"{datetime.now().year}-{time_str}" if '-' in time_str else f"{datetime.now().year}-{datetime.now().month}-{datetime.now().day} {time_str}"
                create_time = time_str
                content = re.sub(pattern, '', line).strip()
                break
        user_patterns = [
            r'([^\sï¼š-]+)[ï¼š-]',
            r'^([^\[\]]+)\s',
            r'^\[([^\]]+)\]',
            r'^<([^>]+)>'
        ]
        for pattern in user_patterns:
            user_match = re.search(pattern, content)
            if user_match:
                user_id = user_match.group(1).strip()
                content = re.sub(pattern, '', content).strip()
                break
        game_module = "æœªåˆ†ç±»"
        for module, keywords in module_keywords.items():
            if any(keyword in content for keyword in keywords):
                game_module = module
                break
        structured_data.append({
            "chat_id": chat_id,
            "create_time": create_time,
            "user_id": user_id,
            "content": content,
            "game_module": game_module
        })
        chat_id += 1
    df = pd.DataFrame(structured_data)
    df['create_time'] = pd.to_datetime(df['create_time'], errors='coerce')
    df['content'] = df['content'].fillna('')
    df['game_module'] = df['game_module'].fillna('æœªåˆ†ç±»')
    return df

def parse_csv_chat(csv_file, custom_module_rules):
    try:
        df = pd.read_csv(csv_file)
        required_cols = ['content']
        if not all(col in df.columns for col in required_cols):
            st.error("âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å« 'content' åˆ—ï¼ˆèŠå¤©å†…å®¹ï¼‰")
            return None
        if 'chat_id' not in df.columns:
            df['chat_id'] = range(1, len(df)+1)
        if 'create_time' not in df.columns:
            df['create_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        if 'user_id' not in df.columns:
            df['user_id'] = [f"user{random.randint(1, 500)}" for _ in range(len(df))]
        if 'game_module' not in df.columns:
            module_keywords = custom_module_rules if custom_module_rules else {
                "è£…å¤‡ç³»ç»Ÿ": ["è£…å¤‡", "æ•°å€¼", "å¼ºåŒ–", "æ‰è½", "å……å€¼", "é“å…·"],
                "ç©æ³•æœºåˆ¶": ["å‰¯æœ¬", "æŠ€èƒ½", "è¿æ‹›", "æ•°å€¼å¹³è¡¡", "æ´»åŠ¨", "éš¾åº¦"],
                "æŠ½å¡ç³»ç»Ÿ": ["æŠ½å¡", "æ¦‚ç‡", "ä¿åº•", "æ–°å¡", "æ¬¡æ•°"],
                "å®¢æœäº’åŠ¨": ["å®¢æœ", "å“åº”", "åé¦ˆ", "è§£å†³", "æ€åº¦"],
                "ç‰ˆæœ¬æ›´æ–°": ["ç‰ˆæœ¬", "æ›´æ–°", "å¡é¡¿", "BUG", "æ›´æ–°åŒ…"],
                "ç¤¾äº¤é—²èŠ": ["ç»„é˜Ÿ", "èŠå¤©", "å¥½å‹", "å…¬ä¼š", "æˆªå›¾"],
                "BUGåé¦ˆ": ["é—ªé€€", "å¡é¡¿", "BUG", "å´©æºƒ", "å¤–æŒ‚", "ç™»å½•"],
                "è¿›åº¦åˆ†äº«": ["å‡çº§", "é€šå…³", "è¿›åº¦", "ä»»åŠ¡", "å¥–åŠ±"]
            }
            def classify_module(content):
                if pd.isna(content):
                    return "æœªåˆ†ç±»"
                for module, keywords in module_keywords.items():
                    if any(keyword in str(content) for keyword in keywords):
                        return module
                return "æœªåˆ†ç±»"
            df['game_module'] = df['content'].apply(classify_module)
        df['create_time'] = pd.to_datetime(df['create_time'], errors='coerce')
        df['content'] = df['content'].fillna('')
        df['game_module'] = df['game_module'].fillna('æœªåˆ†ç±»')
        return df
    except Exception as e:
        st.error(f"âŒ CSVè§£æå¤±è´¥ï¼š{str(e)}")
        return None

def sentiment_analysis(text, positive_threshold, negative_threshold):
    try:
        s = SnowNLP(text)
        base_score = round(s.sentiments, 3)
        perturb = random.uniform(-0.05, 0.05)
        final_score = max(0.0, min(1.0, base_score + perturb))
        final_score = round(final_score, 3)
        if final_score >= positive_threshold:
            return "ç§¯æ", final_score
        elif final_score <= negative_threshold:
            return "æ¶ˆæ", final_score
        else:
            return "ä¸­æ€§", final_score
    except:
        return "ä¸­æ€§", round(random.uniform(0.3, 0.7), 3)

def extract_keywords(texts, topK):
    def preprocess(text):
        text = re.sub(r'[^\u4e00-\u9fa5]', '', text)
        return ' '.join(jieba.cut(text))
    processed_texts = [preprocess(text) for text in texts if text.strip()]
    if not processed_texts:
        return []
    keywords = jieba.analyse.extract_tags(' '.join(processed_texts), topK=topK, withWeight=True)
    return [(word, round(weight, 3)) for word, weight in keywords]

def risk_recognition(text, sentiment_score, negative_threshold, custom_risk_words):
    risk_keywords = custom_risk_words.split(',') if custom_risk_words else ['é—ªé€€', 'å¡é¡¿', 'BUG', 'å´©æºƒ', 'æ— æ³•', 'é”™è¯¯', 'å¤–æŒ‚', 'æ¦‚ç‡ä½', 'ä¸åˆç†', 'å·®']
    risk_keywords = [word.strip() for word in risk_keywords if word.strip()]
    text = text.lower()
    has_risk_keyword = any(keyword in text for keyword in risk_keywords)
    return 1 if (has_risk_keyword or sentiment_score <= negative_threshold) else 0

# ========== å¯è§†åŒ–ä¼˜åŒ–ï¼šç¾è§‚+æ— æŠ¥é”™ ==========
def show_sentiment_analysis(df):
    st.subheader("ğŸ“Š æ¨¡å—AIæƒ…æ„Ÿåˆ†æç»“æœï¼ˆSnowNLPæ¨¡å‹ï¼‰")
    all_modules = df[df['game_module'] != "æœªåˆ†ç±»"]['game_module'].unique().tolist()
    DEFAULT_8_MODULES = ["è£…å¤‡ç³»ç»Ÿ", "ç©æ³•æœºåˆ¶", "æŠ½å¡ç³»ç»Ÿ", "å®¢æœäº’åŠ¨", "ç‰ˆæœ¬æ›´æ–°", "ç¤¾äº¤é—²èŠ", "BUGåé¦ˆ", "è¿›åº¦åˆ†äº«"]
    if not all_modules:
        st.warning("âš ï¸ æš‚æ— æœ‰æ•ˆåˆ†ç±»æ¨¡å—æ•°æ®")
        return
    
    df_core = df[df['game_module'].isin(DEFAULT_8_MODULES)].copy()
    # ========== å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æŒ‡å®šæƒ…æ„Ÿåˆ†ç±»ï¼Œç¡®ä¿ä¸‰åˆ—éƒ½å­˜åœ¨ ==========
    sentiment_categories = ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ']
    df_core['sentiment'] = pd.Categorical(df_core['sentiment'], categories=sentiment_categories)
    
    # ç»Ÿè®¡æƒ…æ„Ÿæ•°æ®
    sentiment_stats = df_core.groupby(['game_module', 'sentiment']).size().unstack(fill_value=0)
    # ç¡®ä¿åˆ—é¡ºåºæ­£ç¡®
    sentiment_stats = sentiment_stats.reindex(columns=sentiment_categories, fill_value=0)
    
    sentiment_stats['æ€»è®¡'] = sentiment_stats.sum(axis=1)
    
    # å®‰å…¨è®¡ç®—å æ¯”
    for col in sentiment_categories:
        if col in sentiment_stats.columns:
            sentiment_stats[f'{col}å æ¯”(%)'] = round(safe_divide(sentiment_stats[col], sentiment_stats['æ€»è®¡']) * 100, 2)
    
    # ========== æ–°å¢è°ƒè¯•è¾“å‡ºï¼šæŸ¥çœ‹åŸå§‹æƒ…æ„Ÿåˆ†å¸ƒ ==========
    st.subheader("ğŸ” è°ƒè¯•ï¼šæ•´ä½“æƒ…æ„Ÿåˆ†å¸ƒ")
    overall_sentiment = df_core['sentiment'].value_counts()
    st.dataframe(overall_sentiment, use_container_width=True)
    
    # 2. ä¼˜åŒ–ç‰ˆæ¶ˆæå æ¯”å±•ç¤ºï¼ˆå¡ç‰‡å¼+å®‰å…¨è¿›åº¦æ¡ï¼‰
    st.subheader("âš ï¸ å„æ¨¡å—æ¶ˆæå æ¯”ï¼ˆé‡ç‚¹å…³æ³¨ï¼‰")
    col_num = 4
    cols = st.columns(col_num)
    module_list = [m for m in DEFAULT_8_MODULES if m in sentiment_stats.index]
    
    for idx, module in enumerate(module_list):
        with cols[idx % col_num]:
            # å®‰å…¨è·å–æ¶ˆæå æ¯”
            neg_rate = sentiment_stats.loc[module, 'æ¶ˆæå æ¯”(%)'] if 'æ¶ˆæå æ¯”(%)' in sentiment_stats.columns else 0.0
            # å®‰å…¨è¿›åº¦æ¡å€¼ï¼ˆé™åˆ¶0-1ï¼‰
            progress_val = clamp_value(safe_divide(neg_rate, 100))
            
            # å¡ç‰‡å¼å±•ç¤ºï¼ˆç¾è§‚ï¼‰
            with st.container(border=True):
                st.markdown(f"### ğŸ® {module}")
                st.progress(progress_val, text=f"æ¶ˆæå æ¯”ï¼š{neg_rate}%")
                
                # é£é™©ç­‰çº§æ ‡ç­¾
                if neg_rate > 30:
                    st.markdown(f"<span style='color:red; font-weight:bold;'>ğŸ”´ é«˜é£é™©</span>", unsafe_allow_html=True)
                elif neg_rate > 15:
                    st.markdown(f"<span style='color:orange; font-weight:bold;'>ğŸŸ¡ ä¸­é£é™©</span>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<span style='color:green; font-weight:bold;'>ğŸŸ¢ ä½é£é™©</span>", unsafe_allow_html=True)
    
    # 3. åˆ†æç»“è®º
    st.subheader("ğŸ’¡ æƒ…æ„Ÿåˆ†æç»“è®ºï¼ˆä¸šåŠ¡ä»·å€¼ï¼‰")
    if 'æ¶ˆæå æ¯”(%)' in sentiment_stats.columns:
        most_negative = sentiment_stats['æ¶ˆæå æ¯”(%)'].idxmax()
        neg_percent = sentiment_stats.loc[most_negative, 'æ¶ˆæå æ¯”(%)']
        st.error(f"ğŸš¨ è´Ÿé¢æƒ…ç»ªæœ€é«˜æ¨¡å—ï¼š{most_negative}ï¼ˆ{neg_percent}%ï¼‰â†’ éœ€ä¼˜å…ˆä¼˜åŒ–")
    if 'ç§¯æå æ¯”(%)' in sentiment_stats.columns:
        most_positive = sentiment_stats['ç§¯æå æ¯”(%)'].idxmax()
        pos_percent = sentiment_stats.loc[most_positive, 'ç§¯æå æ¯”(%)']
        st.success(f"âœ… æ­£é¢æƒ…ç»ªæœ€é«˜æ¨¡å—ï¼š{most_positive}ï¼ˆ{pos_percent}%ï¼‰â†’ å¯å‚è€ƒæˆåŠŸç»éªŒ")

def show_keywords_analysis(df, topK):
    st.subheader(f"ğŸ”‘ æ ¸å¿ƒå…³é”®è¯åˆ†æï¼ˆTF-IDF+jiebaæ¨¡å‹ï¼‰- TOP{topK}å…³é”®è¯")
    all_modules = df[df['game_module'] != "æœªåˆ†ç±»"]['game_module'].unique().tolist()
    DEFAULT_8_MODULES = ["è£…å¤‡ç³»ç»Ÿ", "ç©æ³•æœºåˆ¶", "æŠ½å¡ç³»ç»Ÿ", "å®¢æœäº’åŠ¨", "ç‰ˆæœ¬æ›´æ–°", "ç¤¾äº¤é—²èŠ", "BUGåé¦ˆ", "è¿›åº¦åˆ†äº«"]
    all_modules = [m for m in DEFAULT_8_MODULES if m in all_modules]
    if not all_modules:
        st.warning("âš ï¸ æš‚æ— æœ‰æ•ˆåˆ†ç±»æ¨¡å—æ•°æ®")
        return
    
    col_num = min(4, len(all_modules))
    cols = st.columns(col_num)
    for idx, module in enumerate(all_modules):
        with cols[idx % col_num]:
            module_texts = df[df['game_module'] == module]['content'].tolist()
            keywords = extract_keywords(module_texts, topK)
            if keywords:
                # å¡ç‰‡å¼å…³é”®è¯å±•ç¤º
                with st.container(border=True):
                    st.markdown(f"### ğŸ¯ {module}")
                    # å…³é”®è¯è¡¨æ ¼åŒ–å±•ç¤º
                    keyword_df = pd.DataFrame(keywords, columns=['å…³é”®è¯', 'æƒé‡'])
                    st.dataframe(keyword_df, use_container_width=True, hide_index=True)

def show_risk_analysis(df):
    st.subheader("âš ï¸ é£é™©åé¦ˆåˆ†æï¼ˆå…³é”®è¯+æƒ…æ„Ÿæ¨¡å‹ï¼‰- ä¸šåŠ¡ä»·å€¼ï¼šè¯†åˆ«é«˜é£é™©æ¨¡å—")
    risk_df = df[df['is_risk'] == 1]
    if risk_df.empty:
        st.success("âœ… æš‚æ— é£é™©åé¦ˆæ•°æ®")
        return
    
    risk_count = len(risk_df)
    total_count = len(df)
    risk_rate = round(safe_divide(risk_count, total_count) * 100, 2)
    
    # æ ¸å¿ƒé£é™©æ•°æ®ï¼ˆç¾åŒ–ï¼‰
    col1, col2 = st.columns(2)
    with col1:
        st.metric(label="é£é™©æ¶ˆæ¯æ€»æ•°", value=f"{risk_count}æ¡", delta=f"å æ¯”{risk_rate}%", delta_color="inverse")
    with col2:
        st.metric(label="æ¶‰åŠæ¨¡å—æ•°", value=f"{len(risk_df['game_module'].unique())}ä¸ª")
    
    # é£é™©æ¨¡å—æ’åï¼ˆç¾åŒ–æˆè¡¨æ ¼ï¼‰
    st.subheader("ğŸ“Š é£é™©æ¨¡å—æ’å")
    risk_module = risk_df.groupby('game_module').size().sort_values(ascending=False).reset_index(name='é£é™©æ¡æ•°')
    # æ·»åŠ é£é™©ç­‰çº§
    risk_module['é£é™©ç­‰çº§'] = risk_module['é£é™©æ¡æ•°'].apply(lambda x: 'é«˜é£é™©' if x >= 5 else 'ä¸­é£é™©' if x >= 2 else 'ä½é£é™©')
    # è¡¨æ ¼ç¾åŒ–
    st.dataframe(
        risk_module,
        use_container_width=True,
        column_config={
            "game_module": st.column_config.TextColumn("æ¨¡å—åç§°", width="medium"),
            "é£é™©æ¡æ•°": st.column_config.NumberColumn("é£é™©æ¡æ•°", format="%dæ¡"),
            "é£é™©ç­‰çº§": st.column_config.SelectboxColumn("é£é™©ç­‰çº§", options=["é«˜é£é™©", "ä¸­é£é™©", "ä½é£é™©"])
        }
    )
    
    # é£é™©å»ºè®®ï¼ˆç¾åŒ–ï¼‰
    st.subheader("ğŸ“¢ é£é™©é¢„è­¦å»ºè®®ï¼ˆå¯è½åœ°ï¼‰")
    top_risk_module = risk_module.iloc[0]['game_module'] if not risk_module.empty else 'æ— '
    top_risk_count = risk_module.iloc[0]['é£é™©æ¡æ•°'] if not risk_module.empty else 0
    # å¡ç‰‡å¼å»ºè®®
    with st.container(border=True):
        st.markdown(f"""
        <div style='line-height: 1.8;'>
        <p>ğŸ”´ <strong>ä¼˜å…ˆçº§1</strong>ï¼šç´§æ€¥ä¿®å¤ã€{top_risk_module}ã€‘æ¨¡å—ï¼ˆ{top_risk_count}æ¡é£é™©åé¦ˆï¼‰</p>
        <p>ğŸŸ¡ <strong>ä¼˜å…ˆçº§2</strong>ï¼šé‡ç‚¹ä¼˜åŒ–é«˜é¢‘è´Ÿé¢å…³é”®è¯å¯¹åº”çš„åŠŸèƒ½</p>
        <p>ğŸŸ¢ <strong>ä¼˜å…ˆçº§3</strong>ï¼šåŠ å¼ºæœåŠ¡å™¨ç¨³å®šæ€§å’Œå®¢æœå“åº”æ•ˆç‡ï¼Œé™ä½é£é™©åé¦ˆç‡</p>
        </div>
        """, unsafe_allow_html=True)

# ========== ä¸»æµç¨‹ï¼ˆå®Œå…¨ä¿ç•™ï¼‰==========
def main():
    st.sidebar.header("âš™ï¸ å…¨è‡ªå®šä¹‰é…ç½®ï¼ˆå®æ—¶ç”Ÿæ•ˆï¼‰")
    st.sidebar.subheader("1. æ¨¡å—åŒ¹é…è§„åˆ™é…ç½®")
    default_module_rules = """è£…å¤‡ç³»ç»Ÿ,è£…å¤‡,æ•°å€¼,å¼ºåŒ–,æ‰è½,å……å€¼,é“å…·
ç©æ³•æœºåˆ¶,å‰¯æœ¬,æŠ€èƒ½,è¿æ‹›,æ•°å€¼å¹³è¡¡,æ´»åŠ¨,éš¾åº¦
æŠ½å¡ç³»ç»Ÿ,æŠ½å¡,æ¦‚ç‡,ä¿åº•,æ–°å¡,æ¬¡æ•°
å®¢æœäº’åŠ¨,å®¢æœ,å“åº”,åé¦ˆ,è§£å†³,æ€åº¦
ç‰ˆæœ¬æ›´æ–°,ç‰ˆæœ¬,æ›´æ–°,å¡é¡¿,BUG,æ›´æ–°åŒ…
ç¤¾äº¤é—²èŠ,ç»„é˜Ÿ,èŠå¤©,å¥½å‹,å…¬ä¼š,æˆªå›¾
BUGåé¦ˆ,é—ªé€€,å¡é¡¿,BUG,å´©æºƒ,å¤–æŒ‚,ç™»å½•
è¿›åº¦åˆ†äº«,å‡çº§,é€šå…³,è¿›åº¦,ä»»åŠ¡,å¥–åŠ±"""
    custom_module_rules_text = st.sidebar.text_area(
        "è‡ªå®šä¹‰è§„åˆ™ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
        value=default_module_rules,
        height=200,
        help="æ ¼å¼ï¼šæ¨¡å—å,å…³é”®è¯1,å…³é”®è¯2...\nç¤ºä¾‹ï¼šè£…å¤‡ç³»ç»Ÿ,è£…å¤‡,æ•°å€¼,å¼ºåŒ–,æ‰è½"
    )
    custom_module_rules = {}
    if custom_module_rules_text.strip():
        lines = custom_module_rules_text.strip().split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            parts = line.split(',')
            if len(parts) >= 2:
                module_name = parts[0].strip()
                keywords = [p.strip() for p in parts[1:] if p.strip()]
                if module_name and keywords:
                    custom_module_rules[module_name] = keywords
    st.sidebar.subheader("2. æƒ…æ„Ÿåˆ†æé˜ˆå€¼")
    positive_threshold = st.sidebar.slider("ç§¯æé˜ˆå€¼", 0.5, 0.9, 0.65, 0.05, help="è¶Šé«˜ï¼Œåˆ¤å®šä¸ºç§¯æçš„æ–‡æœ¬è¶Šå°‘")
    negative_threshold = st.sidebar.slider("æ¶ˆæé˜ˆå€¼", 0.9, 0.5, 0.35, 0.05, help="è¶Šä½ï¼Œåˆ¤å®šä¸ºæ¶ˆæçš„æ–‡æœ¬è¶Šå°‘")
    st.sidebar.subheader("3. å…³é”®è¯åˆ†æé…ç½®")
    topK = st.sidebar.number_input("TOPå…³é”®è¯æ•°é‡", 3, 20, 8, 1, help="å»ºè®®5-10")
    st.sidebar.subheader("4. é£é™©è¯†åˆ«é…ç½®")
    default_risk_words = "é—ªé€€,å¡é¡¿,BUG,å´©æºƒ,æ— æ³•,é”™è¯¯,å¤–æŒ‚,æ¦‚ç‡ä½,ä¸åˆç†,å·®"
    custom_risk_words = st.sidebar.text_input("è‡ªå®šä¹‰é£é™©å…³é”®è¯", default_risk_words, help="é€—å·åˆ†éš”ï¼Œå¦‚ï¼šé—ªé€€,å¡é¡¿,BUG")
    
    st.header("ğŸ“¤ æ•°æ®ä¸Šä¼ ï¼ˆCSV/TXTåŒæ ¼å¼æ”¯æŒï¼‰")
    upload_format = st.radio("é€‰æ‹©ä¸Šä¼ æ ¼å¼", ["TXTåŸå§‹èŠå¤©è®°å½•", "CSVç»“æ„åŒ–æ•°æ®"], horizontal=True)
    df = None
    if upload_format == "TXTåŸå§‹èŠå¤©è®°å½•":
        uploaded_file = st.file_uploader("é€‰æ‹©TXTæ–‡ä»¶", type=["txt"])
        if uploaded_file is not None:
            chat_text = uploaded_file.read().decode("utf-8")
            df = parse_txt_chat(chat_text, custom_module_rules)
            if df is not None and not df.empty:
                st.success(f"âœ… æˆåŠŸè§£æTXTæ–‡ä»¶ï¼Œå…±{len(df)}æ¡æœ‰æ•ˆèŠå¤©è®°å½•")
                unclassified_num = len(df[df['game_module'] == "æœªåˆ†ç±»"])
                if unclassified_num > 0:
                    st.info(f"â„¹ï¸ æœªåˆ†ç±»æ•°æ®ï¼š{unclassified_num}æ¡ï¼ˆå¯è¡¥å……æ¨¡å—è§„åˆ™åé‡æ–°ä¸Šä¼ ï¼‰")
    else:
        uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type=["csv"])
        if uploaded_file is not None:
            df = parse_csv_chat(uploaded_file, custom_module_rules)
            if df is not None and not df.empty:
                st.success(f"âœ… æˆåŠŸè§£æCSVæ–‡ä»¶ï¼Œå…±{len(df)}æ¡è®°å½•")
    
    if df is not None and not df.empty:
        df[['sentiment', 'sentiment_score']] = df['content'].apply(
            lambda x: pd.Series(sentiment_analysis(x, positive_threshold, negative_threshold))
        )
        df['is_risk'] = df.apply(
            lambda row: risk_recognition(row['content'], row['sentiment_score'], negative_threshold, custom_risk_words),
            axis=1
        )
        st.header("ğŸ“ˆ æ•°æ®åˆ†æç»“æœ")
        st.subheader("æ•°æ®æ¦‚è§ˆ")
        st.dataframe(df.head(10), use_container_width=True)
        st.write(f"ğŸ“Š æ•°æ®æ€»é‡ï¼š{len(df)}æ¡ | åˆ†ç±»æ¨¡å—æ•°ï¼š{len(df['game_module'].unique())}ä¸ª | æœªåˆ†ç±»æ•°æ®ï¼š{len(df[df['game_module']=='æœªåˆ†ç±»'])}æ¡")
        
        show_sentiment_analysis(df)
        st.divider()
        show_keywords_analysis(df, topK)
        st.divider()
        show_risk_analysis(df)

if __name__ == "__main__":
    jieba.initialize()
    main()

