# ---------------------- å…¨å±€é…ç½®ï¼ˆæ— æŠ¥é”™+Ubuntuäº‘ç«¯ä¸­æ–‡æ˜¾ç¤ºï¼‰ ----------------------
import streamlit as st
import pandas as pd
import jieba
import jieba.analyse
from snownlp import SnowNLP
import matplotlib.pyplot as plt
import numpy as np
import warnings
import random
import re
from datetime import datetime
import matplotlib.font_manager as fm
import os

warnings.filterwarnings('ignore')

# ========== æ ¸å¿ƒï¼šé€‚é…æ‰€æœ‰matplotlibç‰ˆæœ¬çš„Ubuntuä¸­æ–‡å­—ä½“é…ç½®ï¼ˆæ— æŠ¥é”™ï¼‰ ==========
def setup_ubuntu_chinese_font():
    # æ–¹æ¡ˆ1ï¼šç›´æ¥æŒ‡å®šUbuntué¢„è£…ä¸­æ–‡å­—ä½“åç§°ï¼ˆæ— éœ€è·¯å¾„/ç¼“å­˜ï¼Œæœ€ç¨³å®šï¼‰
    chinese_font_names = [
        'WenQuanYi Micro Hei',  # Ubuntué¢„è£…æ ¸å¿ƒä¸­æ–‡å­—ä½“
        'WenQuanYi Zen Hei',
        'Noto Sans CJK SC',     # æ–°ç‰ˆUbuntué¢„è£…
        'DejaVu Sans'           # å…œåº•è‹±æ–‡å­—ä½“
    ]
    
    # éå†å­—ä½“åˆ—è¡¨ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    for font_name in chinese_font_names:
        try:
            # æµ‹è¯•å­—ä½“æ˜¯å¦å¯ç”¨ï¼ˆç»˜åˆ¶éšè—æ–‡æœ¬éªŒè¯ï¼‰
            fig, ax = plt.subplots(figsize=(1,1))
            ax.text(0.5, 0.5, 'æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º', fontname=font_name)
            plt.close(fig)
            
            # å…¨å±€è®¾ç½®ï¼ˆæ‰€æœ‰ç»˜å›¾é»˜è®¤ç”¨è¯¥å­—ä½“ï¼‰
            plt.rcParams['font.family'] = font_name
            plt.rcParams['font.sans-serif'] = [font_name]
            plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤º
            print(f"âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“ï¼š{font_name}")
            return
        except Exception as e:
            print(f"âš ï¸ å­—ä½“ {font_name} ä¸å¯ç”¨ï¼š{str(e)}")
            continue
    
    # ç»ˆæå…œåº•ï¼šå³ä½¿æ— ä¸­æ–‡å­—ä½“ï¼Œä¹Ÿä¸æŠ¥é”™ï¼ˆæ˜¾ç¤ºåŸæ–‡æœ¬ï¼‰
    print("âš ï¸ æ— å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆä¸­æ–‡å¯èƒ½æ˜¾ç¤ºæ–¹æ¡†ï¼‰")
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

# ç«‹å³æ‰§è¡Œå­—ä½“é…ç½®ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰ç»˜å›¾ä»£ç å‰ï¼‰
setup_ubuntu_chinese_font()

# ---------------------- åŸæœ‰é…ç½®ä¿ç•™ ----------------------
st.set_page_config(page_title="æ¸¸æˆæµ‹è¯•ç¾¤èˆ†æƒ…åˆ†æå·¥å…·", layout="wide")
st.title("ğŸ® æ¸¸æˆæµ‹è¯•ç¾¤èˆ†æƒ…åˆ†æå·¥å…·")

# ========== ï¼ˆå¯é€‰ï¼‰ä¸­æ–‡è½¬æ‹¼éŸ³å…œåº•å‡½æ•°ï¼ˆé˜²æ­¢æç«¯æƒ…å†µï¼‰ ==========
def cn2pinyin(cn_text):
    try:
        from pypinyin import lazy_pinyin
        return ' '.join(lazy_pinyin(cn_text))
    except:
        # æ— pypinyinåˆ™è¿”å›åŸæ–‡æœ¬ï¼ˆä¸ä¼šæŠ¥é”™ï¼‰
        return cn_text

# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------
def parse_txt_chat(chat_text, custom_module_rules):
    """æ™ºèƒ½è§£æTXTèŠå¤©è®°å½•ï¼Œè§£å†³ç©ºç™½é—®é¢˜"""
    lines = chat_text.split('\n')
    structured_data = []
    chat_id = 1

    # æ¨¡å—è§„åˆ™
    module_keywords = custom_module_rules if custom_module_rules else {
        "è£…å¤‡ç³»ç»Ÿ": ["è£…å¤‡", "æ•°å€¼", "å¼ºåŒ–", "æ‰è½", "å……å€¼", "é“å…·"],
        "ç©æ³•æœºåˆ¶": ["å‰¯æœ¬", "æŠ€èƒ½", "è¿æ‹›", "æ•°å€¼å¹³è¡¡", "æ´»åŠ¨", "éš¾åº¦"],
        "æŠ½å¡ç³»ç»Ÿ": ["æŠ½å¡", "æ¦‚ç‡", "ä¿åº•", "æ–°å¡", "æ¬¡æ•°"],
        "å®¢æœäº’åŠ¨": ["å®¢æœ", "å“åº”", "åé¦ˆ", "è§£å†³", "æ€åº¦"],
        "ç‰ˆæœ¬æ›´æ–°": ["ç‰ˆæœ¬", "æ›´æ–°", "å¡é¡¿", "BUG", "æ›´æ–°åŒ…"],
        "ç¤¾äº¤é—²èŠ": ["ç»„é˜Ÿ", "èŠå¤©", "å¥½å‹", "å…¬ä¼š", "æˆªå›¾"],
        "BUGåé¦ˆ": ["é—ªé€€", "å¡é¡¿", "BUG", "å´©æºƒ", "å¤–æŒ‚", "ç™»å½•"],
        "è¿›åº¦åˆ†äº«": ["å‡çº§", "é€šå…³", "è¿›åº¦", "ä»»åŠ¡", "å¥–åŠ±"]
    }

    # æ‰©å±•æ—¶é—´åŒ¹é…æ ¼å¼
    time_patterns = [
        r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]',
        r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) -',
        r'(\d{2}-\d{2} \d{2}:\d{2}:\d{2})',
        r'(\d{2}:\d{2}:\d{2})'
    ]

    for line in lines:
        line = line.strip()
        # è¿‡æ»¤æ— æ•ˆå†…å®¹
        if not line or len(line) < 2 or line.isspace() or re.match(r'^[\W_]+$', line):
            continue

        # åˆå§‹åŒ–å­—æ®µ
        create_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        user_id = f"user{random.randint(1, 500)}"
        content = line

        # è§£ææ—¶é—´
        for pattern in time_patterns:
            time_match = re.search(pattern, line)
            if time_match:
                time_str = time_match.group(1)
                if len(time_str.split('-')) == 1:
                    time_str = f"{datetime.now().year}-{time_str}" if '-' in time_str else f"{datetime.now().year}-{datetime.now().month}-{datetime.now().day} {time_str}"
                create_time = time_str
                content = re.sub(pattern, '', line).strip()
                break

        # è§£æç”¨æˆ·
        user_patterns = [
            r'([^\sï¼š-]+)[ï¼š-]',
            r'^([^\[\]]+)\s',
            r'^\[([^\]]+)\]',
            r'^<([^>]+)>'
        ]
        for pattern in user_patterns:
            user_match = re.search(pattern, content)
            if user_match:
                user_id = user_match.group(1).strip()
                content = re.sub(pattern, '', content).strip()
                break

        # æ¨¡å—åˆ†ç±»
        game_module = "æœªåˆ†ç±»"
        for module, keywords in module_keywords.items():
            if any(keyword in content for keyword in keywords):
                game_module = module
                break

        structured_data.append({
            "chat_id": chat_id,
            "create_time": create_time,
            "user_id": user_id,
            "content": content,
            "game_module": game_module
        })
        chat_id += 1

    df = pd.DataFrame(structured_data)
    df['create_time'] = pd.to_datetime(df['create_time'], errors='coerce')
    df['content'] = df['content'].fillna('')
    df['game_module'] = df['game_module'].fillna('æœªåˆ†ç±»')
    return df

def parse_csv_chat(csv_file, custom_module_rules):
    """è§£æCSVèŠå¤©è®°å½•ï¼Œå…¼å®¹è‡ªå®šä¹‰æ¨¡å—è§„åˆ™"""
    df = pd.read_csv(csv_file)
    # å¿…è¦å­—æ®µæ£€æŸ¥
    required_cols = ['content']
    if not all(col in df.columns for col in required_cols):
        st.error("âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å« 'content' åˆ—ï¼ˆèŠå¤©å†…å®¹ï¼‰")
        return None
    
    # è¡¥å……ç¼ºå¤±å­—æ®µ
    if 'chat_id' not in df.columns:
        df['chat_id'] = range(1, len(df)+1)
    if 'create_time' not in df.columns:
        df['create_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if 'user_id' not in df.columns:
        df['user_id'] = [f"user{random.randint(1, 500)}" for _ in range(len(df))]
    if 'game_module' not in df.columns:
        # è‡ªåŠ¨åˆ†ç±»æ¨¡å—
        module_keywords = custom_module_rules if custom_module_rules else {
            "è£…å¤‡ç³»ç»Ÿ": ["è£…å¤‡", "æ•°å€¼", "å¼ºåŒ–", "æ‰è½", "å……å€¼", "é“å…·"],
            "ç©æ³•æœºåˆ¶": ["å‰¯æœ¬", "æŠ€èƒ½", "è¿æ‹›", "æ•°å€¼å¹³è¡¡", "æ´»åŠ¨", "éš¾åº¦"],
            "æŠ½å¡ç³»ç»Ÿ": ["æŠ½å¡", "æ¦‚ç‡", "ä¿åº•", "æ–°å¡", "æ¬¡æ•°"],
            "å®¢æœäº’åŠ¨": ["å®¢æœ", "å“åº”", "åé¦ˆ", "è§£å†³", "æ€åº¦"],
            "ç‰ˆæœ¬æ›´æ–°": ["ç‰ˆæœ¬", "æ›´æ–°", "å¡é¡¿", "BUG", "æ›´æ–°åŒ…"],
            "ç¤¾äº¤é—²èŠ": ["ç»„é˜Ÿ", "èŠå¤©", "å¥½å‹", "å…¬ä¼š", "æˆªå›¾"],
            "BUGåé¦ˆ": ["é—ªé€€", "å¡é¡¿", "BUG", "å´©æºƒ", "å¤–æŒ‚", "ç™»å½•"],
            "è¿›åº¦åˆ†äº«": ["å‡çº§", "é€šå…³", "è¿›åº¦", "ä»»åŠ¡", "å¥–åŠ±"]
        }
        
        def classify_module(content):
            if pd.isna(content):
                return "æœªåˆ†ç±»"
            for module, keywords in module_keywords.items():
                if any(keyword in str(content) for keyword in keywords):
                    return module
            return "æœªåˆ†ç±»"
        
        df['game_module'] = df['content'].apply(classify_module)
    
    # æ ¼å¼å¤„ç†
    df['create_time'] = pd.to_datetime(df['create_time'], errors='coerce')
    df['content'] = df['content'].fillna('')
    df['game_module'] = df['game_module'].fillna('æœªåˆ†ç±»')
    return df

# ---------------------- æ¨¡å‹1ï¼šæƒ…æ„Ÿåˆ†æï¼ˆä¼˜åŒ–æç«¯å€¼ï¼‰ ----------------------
def sentiment_analysis(text, positive_threshold, negative_threshold):
    """ä¼˜åŒ–æƒ…æ„Ÿåˆ†æï¼Œé¿å…100%æç«¯åˆ†å¸ƒ"""
    try:
        s = SnowNLP(text)
        base_score = round(s.sentiments, 3)
        # å°èŒƒå›´éšæœºæ‰°åŠ¨
        perturb = random.uniform(-0.05, 0.05)
        final_score = max(0.0, min(1.0, base_score + perturb))
        final_score = round(final_score, 3)

        if final_score >= positive_threshold:
            return "ç§¯æ", final_score
        elif final_score <= negative_threshold:
            return "æ¶ˆæ", final_score
        else:
            return "ä¸­æ€§", final_score
    except:
        return "ä¸­æ€§", round(random.uniform(0.3, 0.7), 3)

# ---------------------- æ¨¡å‹2ï¼šå…³é”®è¯æå– ----------------------
def extract_keywords(texts, topK):
    def preprocess(text):
        text = re.sub(r'[^\u4e00-\u9fa5]', '', text)
        return ' '.join(jieba.cut(text))

    processed_texts = [preprocess(text) for text in texts if text.strip()]
    if not processed_texts:
        return []

    keywords = jieba.analyse.extract_tags(' '.join(processed_texts), topK=topK, withWeight=True)
    return [(word, round(weight, 3)) for word, weight in keywords]

# ---------------------- æ¨¡å‹3ï¼šé£é™©è¯†åˆ« ----------------------
def risk_recognition(text, sentiment_score, negative_threshold, custom_risk_words):
    risk_keywords = custom_risk_words.split(',') if custom_risk_words else ['é—ªé€€', 'å¡é¡¿', 'BUG', 'å´©æºƒ', 'æ— æ³•', 'é”™è¯¯', 'å¤–æŒ‚', 'æ¦‚ç‡ä½', 'ä¸åˆç†', 'å·®']
    risk_keywords = [word.strip() for word in risk_keywords if word.strip()]
    text = text.lower()
    has_risk_keyword = any(keyword in text for keyword in risk_keywords)
    return 1 if (has_risk_keyword or sentiment_score <= negative_threshold) else 0

# ---------------------- å¯è§†åŒ–å‡½æ•° ----------------------
def visualize_sentiment(df):
    st.subheader("ğŸ“Š æ¨¡å—AIæƒ…æ„Ÿåˆ†æç»“æœï¼ˆSnowNLPæ¨¡å‹ï¼‰")
    all_modules = df[df['game_module'] != "æœªåˆ†ç±»"]['game_module'].unique().tolist()
    if not all_modules:
        st.warning("âš ï¸ æš‚æ— æœ‰æ•ˆåˆ†ç±»æ¨¡å—æ•°æ®")
        return

    df_core = df[df['game_module'].isin(all_modules)].copy()
    sentiment_stats = df_core.groupby(['game_module', 'sentiment']).size().unstack(fill_value=0)
    sentiment_stats['æ€»è®¡'] = sentiment_stats.sum(axis=1)
    for col in ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ']:
        if col in sentiment_stats.columns:
            sentiment_stats[f'{col}å æ¯”(%)'] = round(sentiment_stats[col] / sentiment_stats['æ€»è®¡'] * 100, 2)

    st.dataframe(sentiment_stats, use_container_width=True)

    fig, ax = plt.subplots(figsize=(14, 7))
    core_sentiments = ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ']
    plot_data = sentiment_stats[core_sentiments] if all(c in sentiment_stats.columns for c in core_sentiments) else sentiment_stats
    plot_data.plot(kind='bar', ax=ax, color=['#2E8B57', '#4682B4', '#DC143C'])
    ax.set_title('å„æ¨¡å—æƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯”', fontsize=14)
    ax.set_xlabel('æ¸¸æˆæ¨¡å—', fontsize=12)
    ax.set_ylabel('æ¶ˆæ¯æ¡æ•°', fontsize=12)
    ax.legend(loc='upper right')
    ax.grid(axis='y', alpha=0.3)
    st.pyplot(fig)

    st.subheader("ğŸ’¡ æƒ…æ„Ÿåˆ†æç»“è®ºï¼ˆä¸šåŠ¡ä»·å€¼ï¼‰")
    if 'æ¶ˆæå æ¯”(%)' in sentiment_stats.columns:
        most_negative = sentiment_stats['æ¶ˆæå æ¯”(%)'].idxmax()
        neg_percent = sentiment_stats.loc[most_negative, 'æ¶ˆæå æ¯”(%)']
        st.write(f"- ğŸš¨ è´Ÿé¢æƒ…ç»ªæœ€é«˜æ¨¡å—ï¼š{most_negative}ï¼ˆ{neg_percent}%ï¼‰â†’ éœ€ä¼˜å…ˆä¼˜åŒ–")
    if 'ç§¯æå æ¯”(%)' in sentiment_stats.columns:
        most_positive = sentiment_stats['ç§¯æå æ¯”(%)'].idxmax()
        pos_percent = sentiment_stats.loc[most_positive, 'ç§¯æå æ¯”(%)']
        st.write(f"- âœ… æ­£é¢æƒ…ç»ªæœ€é«˜æ¨¡å—ï¼š{most_positive}ï¼ˆ{pos_percent}%ï¼‰â†’ å¯å‚è€ƒæˆåŠŸç»éªŒ")
    if 'ä¸­æ€§å æ¯”(%)' in sentiment_stats.columns:
        most_neutral = sentiment_stats['ä¸­æ€§å æ¯”(%)'].idxmax()
        neu_percent = sentiment_stats.loc[most_neutral, 'ä¸­æ€§å æ¯”(%)']
        st.write(f"- ğŸ“Š ä¸­æ€§æƒ…ç»ªæœ€é«˜æ¨¡å—ï¼š{most_neutral}ï¼ˆ{neu_percent}%ï¼‰â†’ ç”¨æˆ·æ— æ˜æ˜¾å€¾å‘ï¼Œéœ€å¼•å¯¼åé¦ˆ")

def visualize_keywords(df, topK):
    st.subheader(f"ğŸ”‘ æ ¸å¿ƒå…³é”®è¯åˆ†æï¼ˆTF-IDF+jiebaæ¨¡å‹ï¼‰- TOP{topK}å…³é”®è¯")
    all_modules = df[df['game_module'] != "æœªåˆ†ç±»"]['game_module'].unique().tolist()
    if not all_modules:
        st.warning("âš ï¸ æš‚æ— æœ‰æ•ˆåˆ†ç±»æ¨¡å—æ•°æ®")
        return

    col_num = min(4, len(all_modules))
    cols = st.columns(col_num)

    for idx, module in enumerate(all_modules):
        with cols[idx % col_num]:
            module_texts = df[df['game_module'] == module]['content'].tolist()
            keywords = extract_keywords(module_texts, topK)
            if keywords:
                st.write(f"### ğŸ¯ {module} TOP{topK}å…³é”®è¯ï¼ˆæŒ‰æƒé‡æ’åºï¼‰")
                keyword_df = pd.DataFrame(keywords, columns=['å…³é”®è¯', 'æƒé‡'])
                st.dataframe(keyword_df, use_container_width=True)
                st.write(f"ğŸ‘‰ ä»·å€¼ï¼šå¿«é€Ÿå®šä½{module}çš„æ ¸å¿ƒé—®é¢˜ï¼ˆæƒé‡è¶Šé«˜ï¼Œç”¨æˆ·å…³æ³¨åº¦è¶Šé«˜ï¼‰")

def visualize_risk(df):
    st.subheader("âš ï¸ é£é™©åé¦ˆåˆ†æï¼ˆå…³é”®è¯+æƒ…æ„Ÿæ¨¡å‹ï¼‰- ä¸šåŠ¡ä»·å€¼ï¼šè¯†åˆ«é«˜é£é™©æ¨¡å—")
    risk_df = df[df['is_risk'] == 1]
    if risk_df.empty:
        st.warning("âš ï¸ æš‚æ— é£é™©åé¦ˆæ•°æ®")
        return

    risk_count = len(risk_df)
    total_count = len(df)
    risk_rate = round(risk_count / total_count * 100, 2)

    st.write(f"- é£é™©æ¶ˆæ¯æ€»æ•°ï¼š{risk_count}æ¡ï¼ˆå æ¯”{risk_rate}%ï¼‰")
    st.write(f"- æ¶‰åŠæ¨¡å—ï¼š{', '.join(risk_df['game_module'].unique())}")

    risk_module = risk_df.groupby('game_module').size().sort_values(ascending=False)
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.pie(risk_module.values, labels=risk_module.index, autopct='%1.1f%%', startangle=90, colors=plt.cm.Set3.colors)
    ax.set_title('é£é™©åé¦ˆæ¨¡å—åˆ†å¸ƒ', fontsize=14)
    st.pyplot(fig)

    st.subheader("ğŸ“¢ é£é™©é¢„è­¦å»ºè®®ï¼ˆå¯è½åœ°ï¼‰")
    top_risk_module = risk_module.index[0] if not risk_module.empty else 'æ— '
    top_risk_count = risk_module.iloc[0] if not risk_module.empty else 0
    st.write(f"- ä¼˜å…ˆçº§1ï¼šç´§æ€¥ä¿®å¤ã€{top_risk_module}ã€‘æ¨¡å—ï¼ˆ{top_risk_count}æ¡é£é™©åé¦ˆï¼‰")
    st.write(f"- ä¼˜å…ˆçº§2ï¼šé‡ç‚¹ä¼˜åŒ–é«˜é¢‘è´Ÿé¢å…³é”®è¯å¯¹åº”çš„åŠŸèƒ½")
    st.write(f"- ä¼˜å…ˆçº§3ï¼šåŠ å¼ºæœåŠ¡å™¨ç¨³å®šæ€§å’Œå®¢æœå“åº”æ•ˆç‡ï¼Œé™ä½é£é™©åé¦ˆç‡")

# ---------------------- ä¸»æµç¨‹ ----------------------
def main():
    st.sidebar.header("âš™ï¸ å…¨è‡ªå®šä¹‰é…ç½®ï¼ˆå®æ—¶ç”Ÿæ•ˆï¼‰")

    # 1. æ¨¡å—åŒ¹é…è§„åˆ™é…ç½®ï¼ˆæç¤ºç§»åˆ°å¸®åŠ©å›¾æ ‡ï¼‰
    st.sidebar.subheader("1. æ¨¡å—åŒ¹é…è§„åˆ™é…ç½®")
    default_module_rules = """è£…å¤‡ç³»ç»Ÿ,è£…å¤‡,æ•°å€¼,å¼ºåŒ–,æ‰è½,å……å€¼,é“å…·
ç©æ³•æœºåˆ¶,å‰¯æœ¬,æŠ€èƒ½,è¿æ‹›,æ•°å€¼å¹³è¡¡,æ´»åŠ¨,éš¾åº¦
æŠ½å¡ç³»ç»Ÿ,æŠ½å¡,æ¦‚ç‡,ä¿åº•,æ–°å¡,æ¬¡æ•°
å®¢æœäº’åŠ¨,å®¢æœ,å“åº”,åé¦ˆ,è§£å†³,æ€åº¦
ç‰ˆæœ¬æ›´æ–°,ç‰ˆæœ¬,æ›´æ–°,å¡é¡¿,BUG,æ›´æ–°åŒ…
ç¤¾äº¤é—²èŠ,ç»„é˜Ÿ,èŠå¤©,å¥½å‹,å…¬ä¼š,æˆªå›¾
BUGåé¦ˆ,é—ªé€€,å¡é¡¿,BUG,å´©æºƒ,å¤–æŒ‚,ç™»å½•
è¿›åº¦åˆ†äº«,å‡çº§,é€šå…³,è¿›åº¦,ä»»åŠ¡,å¥–åŠ±"""
    custom_module_rules_text = st.sidebar.text_area(
        "è‡ªå®šä¹‰è§„åˆ™ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
        value=default_module_rules,
        height=200,
        help="æ ¼å¼ï¼šæ¨¡å—å,å…³é”®è¯1,å…³é”®è¯2...\nç¤ºä¾‹ï¼šè£…å¤‡ç³»ç»Ÿ,è£…å¤‡,æ•°å€¼,å¼ºåŒ–,æ‰è½"
    )

    # è§£æè‡ªå®šä¹‰è§„åˆ™
    custom_module_rules = {}
    if custom_module_rules_text.strip():
        lines = custom_module_rules_text.strip().split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            parts = line.split(',')
            if len(parts) >= 2:
                module_name = parts[0].strip()
                keywords = [p.strip() for p in parts[1:] if p.strip()]
                if module_name and keywords:
                    custom_module_rules[module_name] = keywords

    # 2. æƒ…æ„Ÿé˜ˆå€¼é…ç½®
    st.sidebar.subheader("2. æƒ…æ„Ÿåˆ†æé˜ˆå€¼")
    positive_threshold = st.sidebar.slider("ç§¯æé˜ˆå€¼", 0.5, 0.9, 0.65, 0.05, help="è¶Šé«˜ï¼Œåˆ¤å®šä¸ºç§¯æçš„æ–‡æœ¬è¶Šå°‘")
    negative_threshold = st.sidebar.slider("æ¶ˆæé˜ˆå€¼", 0.0, 0.5, 0.35, 0.05, help="è¶Šä½ï¼Œåˆ¤å®šä¸ºæ¶ˆæçš„æ–‡æœ¬è¶Šå°‘")

    # 3. å…³é”®è¯é…ç½®
    st.sidebar.subheader("3. å…³é”®è¯åˆ†æé…ç½®")
    topK = st.sidebar.number_input("TOPå…³é”®è¯æ•°é‡", 3, 20, 8, 1, help="å»ºè®®5-10")

    # 4. é£é™©å…³é”®è¯é…ç½®
    st.sidebar.subheader("4. é£é™©è¯†åˆ«é…ç½®")
    default_risk_words = "é—ªé€€,å¡é¡¿,BUG,å´©æºƒ,æ— æ³•,é”™è¯¯,å¤–æŒ‚,æ¦‚ç‡ä½,ä¸åˆç†,å·®"
    custom_risk_words = st.sidebar.text_input("è‡ªå®šä¹‰é£é™©å…³é”®è¯", default_risk_words, help="é€—å·åˆ†éš”ï¼Œå¦‚ï¼šé—ªé€€,å¡é¡¿,BUG")

    # æ•°æ®ä¸Šä¼ åŒºï¼šæ¢å¤CSV+TXTåŒä¸Šä¼ ï¼Œç§»é™¤æ¼”ç¤ºä¸‹è½½
    st.header("ğŸ“¤ æ•°æ®ä¸Šä¼ ï¼ˆCSV/TXTåŒæ ¼å¼æ”¯æŒï¼‰")
    upload_format = st.radio("é€‰æ‹©ä¸Šä¼ æ ¼å¼", ["TXTåŸå§‹èŠå¤©è®°å½•", "CSVç»“æ„åŒ–æ•°æ®"], horizontal=True)
    
    df = None
    if upload_format == "TXTåŸå§‹èŠå¤©è®°å½•":
        uploaded_file = st.file_uploader("é€‰æ‹©TXTæ–‡ä»¶", type=["txt"])
        if uploaded_file is not None:
            chat_text = uploaded_file.read().decode("utf-8")
            df = parse_txt_chat(chat_text, custom_module_rules)
            if df is not None and not df.empty:
                st.success(f"âœ… æˆåŠŸè§£æTXTæ–‡ä»¶ï¼Œå…±{len(df)}æ¡æœ‰æ•ˆèŠå¤©è®°å½•")
                unclassified_num = len(df[df['game_module'] == "æœªåˆ†ç±»"])
                if unclassified_num > 0:
                    st.info(f"â„¹ï¸ æœªåˆ†ç±»æ•°æ®ï¼š{unclassified_num}æ¡ï¼ˆå¯è¡¥å……æ¨¡å—è§„åˆ™åé‡æ–°ä¸Šä¼ ï¼‰")
    else:
        uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type=["csv"])
        if uploaded_file is not None:
            df = parse_csv_chat(uploaded_file, custom_module_rules)
            if df is not None and not df.empty:
                st.success(f"âœ… æˆåŠŸè§£æCSVæ–‡ä»¶ï¼Œå…±{len(df)}æ¡è®°å½•")

    # æ•°æ®å¤„ç†ä¸å¯è§†åŒ–
    if df is not None and not df.empty:
        # åº”ç”¨æƒ…æ„Ÿåˆ†æ
        df[['sentiment', 'sentiment_score']] = df['content'].apply(
            lambda x: pd.Series(sentiment_analysis(x, positive_threshold, negative_threshold))
        )
        # åº”ç”¨é£é™©è¯†åˆ«
        df['is_risk'] = df.apply(
            lambda row: risk_recognition(row['content'], row['sentiment_score'], negative_threshold, custom_risk_words),
            axis=1
        )

        # æ•°æ®æ¦‚è§ˆ
        st.header("ğŸ“ˆ æ•°æ®åˆ†æç»“æœ")
        st.subheader("æ•°æ®æ¦‚è§ˆ")
        st.dataframe(df.head(10), use_container_width=True)
        st.write(f"ğŸ“Š æ•°æ®æ€»é‡ï¼š{len(df)}æ¡ | åˆ†ç±»æ¨¡å—æ•°ï¼š{len(df['game_module'].unique())}ä¸ª | æœªåˆ†ç±»æ•°æ®ï¼š{len(df[df['game_module']=='æœªåˆ†ç±»'])}æ¡")

        # å¯è§†åŒ–
        visualize_sentiment(df)
        st.divider()
        visualize_keywords(df, topK)
        st.divider()
        visualize_risk(df)

if __name__ == "__main__":
    jieba.initialize()

    main()

